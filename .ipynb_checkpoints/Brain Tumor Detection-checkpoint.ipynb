{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvtmr77WsVYw"
      },
      "source": [
        "# Brain Tumor Detection Using a Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD62_rL0sVY5"
      },
      "source": [
        "**About the Brain MRI Images dataset:**<br>\n",
        "The dataset contains 2 folders: yes and no which contains 253 Brain MRI Images. The folder yes contains 155 Brain MRI Images that are tumorous and the folder no contains 98 Brain MRI Images that are non-tumorous. You can find it [here](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83NfLX9tsVY9"
      },
      "source": [
        "## Import Necessary Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "p7mFAiFpsVY_"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import imutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from os import listdir\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRkVGtjfsVZC"
      },
      "source": [
        "## Data Preparation & Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zmVn4ssZsVZF"
      },
      "outputs": [],
      "source": [
        "def crop_brain_contour(image, plot=False):\n",
        "\n",
        "    #import imutils\n",
        "    #import cv2\n",
        "    #from matplotlib import pyplot as plt\n",
        "\n",
        "    # Convert the image to grayscale, and blur it slightly\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Threshold the image, then perform a series of erosions +\n",
        "    # dilations to remove any small regions of noise\n",
        "    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
        "    thresh = cv2.erode(thresh, None, iterations=2)\n",
        "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
        "\n",
        "    # Find contours in thresholded image, then grab the largest one\n",
        "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cnts = imutils.grab_contours(cnts)\n",
        "    c = max(cnts, key=cv2.contourArea)\n",
        "\n",
        "\n",
        "    # Find the extreme points\n",
        "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "\n",
        "    # crop new image out of the original image using the four extreme points (left, right, top, bottom)\n",
        "    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]\n",
        "\n",
        "    if plot:\n",
        "        plt.figure()\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(image)\n",
        "\n",
        "        plt.tick_params(axis='both', which='both',\n",
        "                        top=False, bottom=False, left=False, right=False,\n",
        "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "\n",
        "        plt.title('Original Image')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(new_image)\n",
        "\n",
        "        plt.tick_params(axis='both', which='both',\n",
        "                        top=False, bottom=False, left=False, right=False,\n",
        "                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "\n",
        "        plt.title('Cropped Image')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    return new_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtlwgzRXsVZH"
      },
      "source": [
        "In order to better understand what it's doing, let's grab an image from the dataset and apply this cropping function to see the result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "etwJ_koEsVZI",
        "outputId": "24e11476-f14b-4674-c96b-f3d49e7cfb5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Erreur : L'image n'a pas été trouvée. Vérifiez le chemin.\n"
          ]
        }
      ],
      "source": [
        "ex_img = cv2.imread('yes/Y1.jpg')\n",
        "ex_new_img = crop_brain_contour(ex_img, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jXWnnMvsVZM"
      },
      "source": [
        "### Load up the data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdi36N32sVZN"
      },
      "source": [
        "The following function takes two arguments, the first one is a list of directory paths for the folders 'yes' and 'no' that contain the image data and the second argument is the image size, and for every image in both directories and does the following:\n",
        "1. Read the image.\n",
        "2. Crop the part of the image representing only the brain.\n",
        "3. Resize the image (because the images in the dataset come in different sizes (meaning width, height and # of channels). So, we want all of our images to be (240, 240, 3) to feed it as an input to the neural network.\n",
        "4. Apply normalization because we want pixel values to be scaled to the range 0-1.\n",
        "5. Append the image to <i>X</i> and its label to <i>y</i>.<br>\n",
        "\n",
        "After that, Shuffle <i>X</i> and <i>y</i>, because the data is ordered (meaning the arrays contains the first part belonging to one class and the second part belonging to the other class, and we don't want that).<br>\n",
        "Finally, Return <i>X</i> and <i>y</i>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "W_ki-qKNsVZO"
      },
      "outputs": [],
      "source": [
        "def load_data(dir_list, image_size):\n",
        "    \"\"\"\n",
        "    Read images, resize and normalize them.\n",
        "    Arguments:\n",
        "        dir_list: list of strings representing file directories.\n",
        "    Returns:\n",
        "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
        "        y: A numpy array with shape = (#_examples, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    # load all images in a directory\n",
        "    X = []\n",
        "    y = []\n",
        "    image_width, image_height = image_size\n",
        "\n",
        "    for directory in dir_list:\n",
        "        for filename in listdir(directory):\n",
        "            # load the image\n",
        "            image = cv2.imread(directory + '\\\\' + filename)\n",
        "            # crop the brain and ignore the unnecessary rest part of the image\n",
        "            image = crop_brain_contour(image, plot=False)\n",
        "            # resize image\n",
        "            image = cv2.resize(image, dsize=(image_width, image_height), interpolation=cv2.INTER_CUBIC)\n",
        "            # normalize values\n",
        "            image = image / 255.\n",
        "            # convert image to numpy array and append it to X\n",
        "            X.append(image)\n",
        "            # append a value of 1 to the target array if the image\n",
        "            # is in the folder named 'yes', otherwise append 0.\n",
        "            if directory[-3:] == 'yes':\n",
        "                y.append([1])\n",
        "            else:\n",
        "                y.append([0])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Shuffle the data\n",
        "    X, y = shuffle(X, y)\n",
        "\n",
        "    print(f'Number of examples is: {len(X)}')\n",
        "    print(f'X shape is: {X.shape}')\n",
        "    print(f'y shape is: {y.shape}')\n",
        "\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGWYZ0ILsVZP"
      },
      "source": [
        "Load up the data that we augmented earlier in the Data Augmentation notebook.<br>\n",
        "**Note:** the augmented data directory contains not only the new generated images but also the original images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "P0I7mAcIsVZP",
        "outputId": "4425fd03-5e31-4a8a-9152-242b03e17b20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'D:\\\\Brain-Tumor-Detection-master\\\\augmented data\\\\yes'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-24-3615799354.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mIMG_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_HEIGHT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maugmented_yes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmented_no\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIMG_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_HEIGHT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-23-673204913.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(dir_list, image_size)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;31m# load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\\\'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Brain-Tumor-Detection-master\\\\augmented data\\\\yes'"
          ]
        }
      ],
      "source": [
        "# Chemins absolus corrigés\n",
        "augmented_yes = r'D:\\Brain-Tumor-Detection-master\\augmented data\\yes'\n",
        "augmented_no = r'D:\\Brain-Tumor-Detection-master\\augmented data\\no'\n",
        "\n",
        "IMG_WIDTH, IMG_HEIGHT = (240, 240)\n",
        "\n",
        "X, y = load_data([augmented_yes, augmented_no], (IMG_WIDTH, IMG_HEIGHT))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7_P-NOAsVZQ"
      },
      "source": [
        "As we see, we have 2065 images. Each images has a shape of **(240, 240, 3)=(image_width, image_height, number_of_channels)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaWMI26JsVZR"
      },
      "source": [
        "### Plot sample images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azMNkAPxsVZR"
      },
      "outputs": [],
      "source": [
        "def plot_sample_images(X, y, n=50):\n",
        "    \"\"\"\n",
        "    Plots n sample images for both values of y (labels).\n",
        "    Arguments:\n",
        "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
        "        y: A numpy array with shape = (#_examples, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    for label in [0,1]:\n",
        "        # grab the first n images with the corresponding y values equal to label\n",
        "        images = X[np.argwhere(y == label)]\n",
        "        n_images = images[:n]\n",
        "\n",
        "        columns_n = 10\n",
        "        rows_n = int(n/ columns_n)\n",
        "\n",
        "        plt.figure(figsize=(20, 10))\n",
        "\n",
        "        i = 1 # current plot\n",
        "        for image in n_images:\n",
        "            plt.subplot(rows_n, columns_n, i)\n",
        "            plt.imshow(image[0])\n",
        "\n",
        "            # remove ticks\n",
        "            plt.tick_params(axis='both', which='both',\n",
        "                            top=False, bottom=False, left=False, right=False,\n",
        "                           labelbottom=False, labeltop=False, labelleft=False, labelright=False)\n",
        "\n",
        "            i += 1\n",
        "\n",
        "        label_to_str = lambda label: \"Yes\" if label == 1 else \"No\"\n",
        "        plt.suptitle(f\"Brain Tumor: {label_to_str(label)}\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NkritY9sVZS"
      },
      "outputs": [],
      "source": [
        "plot_sample_images(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uN88H_rusVZS"
      },
      "source": [
        "### Split the data:\n",
        "Split <i>X</i> and <i>y</i> into training, validation (development) and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzuhXvFWsVZS"
      },
      "outputs": [],
      "source": [
        "def split_data(X, y, test_size=0.2):\n",
        "\n",
        "    \"\"\"\n",
        "    Splits data into training, development and test sets.\n",
        "    Arguments:\n",
        "        X: A numpy array with shape = (#_examples, image_width, image_height, #_channels)\n",
        "        y: A numpy array with shape = (#_examples, 1)\n",
        "    Returns:\n",
        "        X_train: A numpy array with shape = (#_train_examples, image_width, image_height, #_channels)\n",
        "        y_train: A numpy array with shape = (#_train_examples, 1)\n",
        "        X_val: A numpy array with shape = (#_val_examples, image_width, image_height, #_channels)\n",
        "        y_val: A numpy array with shape = (#_val_examples, 1)\n",
        "        X_test: A numpy array with shape = (#_test_examples, image_width, image_height, #_channels)\n",
        "        y_test: A numpy array with shape = (#_test_examples, 1)\n",
        "    \"\"\"\n",
        "\n",
        "    X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=test_size)\n",
        "    X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpSa-Z-KsVZT"
      },
      "source": [
        "Let's use the following way to split:<br>\n",
        "1. 70% of the data for training.\n",
        "2. 15% of the data for validation.\n",
        "3. 15% of the data for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FO5PCqWAsVZT"
      },
      "outputs": [],
      "source": [
        "X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLtVULUbsVZU"
      },
      "outputs": [],
      "source": [
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of development examples = \" + str(X_val.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(y_train.shape))\n",
        "print (\"X_val (dev) shape: \" + str(X_val.shape))\n",
        "print (\"Y_val (dev) shape: \" + str(y_val.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RWKtRHjsVZU"
      },
      "source": [
        "Some helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AdFWIkyusVZV"
      },
      "outputs": [],
      "source": [
        "# Nicely formatted time string\n",
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return f\"{h}:{m}:{round(s,1)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "C7UDNtsPsVZV"
      },
      "outputs": [],
      "source": [
        "def compute_f1_score(y_true, prob):\n",
        "    # convert the vector of probabilities to a target vector\n",
        "    y_pred = np.where(prob > 0.5, 1, 0)\n",
        "\n",
        "    score = f1_score(y_true, y_pred)\n",
        "\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOII_3v2sVZW"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz050yKqsVZW"
      },
      "source": [
        "Let's build a convolutional neural network model:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCQ5eIo8sVZW"
      },
      "source": [
        "<img src='https://github.com/zakariakassemi2000/Detection-Brain-Tumors/blob/main/.ipynb_checkpoints/convnet_architecture.jpg?raw=1'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sMg_0qADsVZX"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shape):\n",
        "    \"\"\"\n",
        "    Arugments:\n",
        "        input_shape: A tuple representing the shape of the input of the model. shape=(image_width, image_height, #_channels)\n",
        "    Returns:\n",
        "        model: A Model object.\n",
        "    \"\"\"\n",
        "    # Define the input placeholder as a tensor with shape input_shape.\n",
        "    X_input = Input(input_shape) # shape=(?, 240, 240, 3)\n",
        "\n",
        "    # Zero-Padding: pads the border of X_input with zeroes\n",
        "    X = ZeroPadding2D((2, 2))(X_input) # shape=(?, 244, 244, 3)\n",
        "\n",
        "    # CONV -> BN -> RELU Block applied to X\n",
        "    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
        "    X = Activation('relu')(X) # shape=(?, 238, 238, 32)\n",
        "\n",
        "    # MAXPOOL\n",
        "    X = MaxPooling2D((4, 4), name='max_pool0')(X) # shape=(?, 59, 59, 32)\n",
        "\n",
        "    # MAXPOOL\n",
        "    X = MaxPooling2D((4, 4), name='max_pool1')(X) # shape=(?, 14, 14, 32)\n",
        "\n",
        "    # FLATTEN X\n",
        "    X = Flatten()(X) # shape=(?, 6272)\n",
        "    # FULLYCONNECTED\n",
        "    X = Dense(1, activation='sigmoid', name='fc')(X) # shape=(?, 1)\n",
        "\n",
        "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
        "    model = Model(inputs = X_input, outputs = X, name='BrainDetectionModel')\n",
        "    model.save('your_model.h5')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fpEqc8tsVZX"
      },
      "source": [
        "Define the image shape:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mpvM9Nv0sVZY"
      },
      "outputs": [],
      "source": [
        "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "r2JOpf6asVZY",
        "outputId": "fce9d329-c2e0-4094-dca1-b3fce43fce2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model = build_model(IMG_SHAPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "oOdA-RJQsVZY",
        "outputId": "698b466c-d489-4062-c01d-e8951a01f3e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"BrainDetectionModel\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"BrainDetectionModel\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m240\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ zero_padding2d_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m244\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mZeroPadding2D\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv0 (\u001b[38;5;33mConv2D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m238\u001b[0m, \u001b[38;5;34m238\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m4,736\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn0 (\u001b[38;5;33mBatchNormalization\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m238\u001b[0m, \u001b[38;5;34m238\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m238\u001b[0m, \u001b[38;5;34m238\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pool0 (\u001b[38;5;33mMaxPooling2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m59\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pool1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ fc (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │         \u001b[38;5;34m6,273\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">240</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ zero_padding2d_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">244</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,736</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bn0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">238</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pool0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pool1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ fc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,273</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,137\u001b[0m (43.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,137</span> (43.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,073\u001b[0m (43.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,073</span> (43.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m64\u001b[0m (256.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> (256.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trWdPDBNsVZa"
      },
      "source": [
        "Compile the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Atmt7pxOsVZa"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jbgKbs8IsVZb"
      },
      "outputs": [],
      "source": [
        "# tensorboard\n",
        "log_file_name = f'brain_tumor_detection_cnn_{int(time.time())}'\n",
        "tensorboard = TensorBoard(log_dir=f'logs/{log_file_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jDbIVqclsVZb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1fCgYY8sVZb"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "scrolled": false,
        "id": "5K2U4RTNsVZk",
        "outputId": "4b131a61-7583-4f05-f0a2-92de76891ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-33-1220414797.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m model.fit(\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Start timer\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    batch_size=32,\n",
        "    epochs=10,\n",
        "    validation_data=(X_val, y_val),\n",
        "\n",
        ")\n",
        "\n",
        "# End timer\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "\n",
        "# Print elapsed time\n",
        "print(f\"Elapsed time: {hms_string(execution_time)}\")\n",
        "\n",
        "# ✅ Save the trained model\n",
        "model.save('your_model.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENPTMC-xsVZk"
      },
      "source": [
        "Let's train for a few more epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzhFNu2jsVZl"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    batch_size=32,\n",
        "    epochs=3,\n",
        "    validation_data=(X_val, y_val),\n",
        "\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = (end_time - start_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgxzOW-GsVZl"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "model.fit(x=X_train, y=y_train, batch_size=32, epochs=3, validation_data=(X_val, y_val), callbacks=[tensorboard])\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = (end_time - start_time)\n",
        "print(f\"Elapsed time: {hms_string(execution_time)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9G3Oe8osVZl"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "model.fit(x=X_train, y=y_train, batch_size=32, epochs=3, validation_data=(X_val, y_val), callbacks=[tensorboard])\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = (end_time - start_time)\n",
        "print(f\"Elapsed time: {hms_string(execution_time)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-9C1kfSsVZm"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "model.fit(x=X_train, y=y_train, batch_size=32, epochs=5, validation_data=(X_val, y_val), callbacks=[tensorboard])\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = (end_time - start_time)\n",
        "print(f\"Elapsed time: {hms_string(execution_time)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwU6yB9GsVZm"
      },
      "outputs": [],
      "source": [
        "history = model.history.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDHLSKeQsVZq"
      },
      "outputs": [],
      "source": [
        "for key in history.keys():\n",
        "    print(key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVMjb-MQsVZr"
      },
      "source": [
        "## Plot Loss & Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JcVC01ksVZs"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(history):\n",
        "\n",
        "    train_loss = history['loss']\n",
        "    val_loss = history['val_loss']\n",
        "    train_acc = history['acc']\n",
        "    val_acc = history['val_acc']\n",
        "\n",
        "    # Loss\n",
        "    plt.figure()\n",
        "    plt.plot(train_loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.figure()\n",
        "    plt.plot(train_acc, label='Training Accuracy')\n",
        "    plt.plot(val_acc, label='Validation Accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMwHA1DTsVZt"
      },
      "source": [
        "**Note:** Since we trained the model using more than model.fit() function call, this made the history only contain the metric values of the epochs for the last call (which was for 5 epochs), so to plot the metric values across the whole process of trianing the model from the beginning, I had to grab the rest of the values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dcdMgvHEsVZt"
      },
      "outputs": [],
      "source": [
        "plot_metrics(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfVdR9D3sVZu"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6BUWaO3sVZv"
      },
      "source": [
        "Let's experiment with the best model (the one with the best validation accuracy):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYW-zD5JsVZw"
      },
      "source": [
        "Concretely, the model at the 23rd iteration with validation accuracy of 91%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVaxX75esVZx"
      },
      "source": [
        "### Load the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6YIDUK3sVZx"
      },
      "outputs": [],
      "source": [
        "best_model = load_model(filepath='models/cnn-parameters-improvement-23-0.91.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WD4arWR6sVZy"
      },
      "outputs": [],
      "source": [
        "best_model.metrics_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1wom5nlsVZy"
      },
      "source": [
        "Evaluate the best model on the testing data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fhBp2ew1sVZ0"
      },
      "outputs": [],
      "source": [
        "loss, acc = best_model.evaluate(x=X_test, y=y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek-gD08usVZ1"
      },
      "source": [
        "### Accuracy of the best model on the testing data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8vyU7MxsVZ1"
      },
      "outputs": [],
      "source": [
        "print (f\"Test Loss = {loss}\")\n",
        "print (f\"Test Accuracy = {acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57rfDVvRsVZ2"
      },
      "source": [
        "### F1 score for the best model on the testing data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "kkhhSOFxsVZ2",
        "outputId": "a386a817-2598-4372-fbc4-2c761111c5f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'best_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-34-701669896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
          ]
        }
      ],
      "source": [
        "y_test_prob = best_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3zejtJZsVZ3"
      },
      "outputs": [],
      "source": [
        "f1score = compute_f1_score(y_test, y_test_prob)\n",
        " print(f\"F1 score: {f1score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHS23glksVZ3"
      },
      "source": [
        "Let's also find the f1 score on the validation data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ7lRa-XsVZ4"
      },
      "outputs": [],
      "source": [
        "y_val_prob = best_model.predict(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Iqp6hENsVZ4"
      },
      "outputs": [],
      "source": [
        "f1score_val = compute_f1_score(y_val, y_val_prob)\n",
        "print(f\"F1 score: {f1score_val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "priYzTuZsVZ5"
      },
      "source": [
        "### Results Interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsGbCZvWsVZ5"
      },
      "source": [
        "Let's remember the percentage of positive and negative examples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwioOReusVZ6"
      },
      "outputs": [],
      "source": [
        "def data_percentage(y):\n",
        "\n",
        "    m=len(y)\n",
        "    n_positive = np.sum(y)\n",
        "    n_negative = m - n_positive\n",
        "\n",
        "    pos_prec = (n_positive* 100.0)/ m\n",
        "    neg_prec = (n_negative* 100.0)/ m\n",
        "\n",
        "    print(f\"Number of examples: {m}\")\n",
        "    print(f\"Percentage of positive examples: {pos_prec}%, number of pos examples: {n_positive}\")\n",
        "    print(f\"Percentage of negative examples: {neg_prec}%, number of neg examples: {n_negative}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZoe_r9csVZ7"
      },
      "outputs": [],
      "source": [
        "# the whole data\n",
        "data_percentage(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDiAc2eZsVZ8"
      },
      "outputs": [],
      "source": [
        "print(\"Training Data:\")\n",
        "data_percentage(y_train)\n",
        "print(\"Validation Data:\")\n",
        "data_percentage(y_val)\n",
        "print(\"Testing Data:\")\n",
        "data_percentage(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NdaxohQsVZ8"
      },
      "source": [
        "As expectred, the percentage of positive examples are around 50%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AEgMXYlsVZ9"
      },
      "source": [
        "# Conclusion:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSXjPbZusVZ-"
      },
      "source": [
        "#### Now, the model detects brain tumor with:<br>\n",
        "**88.7%** accuracy on the **test set**.<br>\n",
        "**0.88** f1 score on the **test set**.<br>\n",
        "These resutls are very good considering that the data is balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axmDokW-sVZ-"
      },
      "source": [
        "**Performance Table:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IULajlCjsVZ-"
      },
      "source": [
        "| <!-- -->  | Validation set | Test set |\n",
        "| --------- | -------------- | -------- |\n",
        "| Accuracy  | 91%            | 89%      |\n",
        "| F1 score  | 0.91           | 0.88     |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrb0U1GusVaC"
      },
      "source": [
        "Hooray!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpDq9p2bsVaC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}